import asyncio
import os
import json
import logging
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta, timezone
from feedgen.feed import FeedGenerator
from google.cloud import storage
from google.oauth2 import service_account
from telethon import TelegramClient
from telethon.sessions import StringSession

# âœ… LOGÅ² KONFIGÅªRACIJA
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# âœ… TELEGRAM PRISIJUNGIMO DUOMENYS
api_id = int(os.getenv("TELEGRAM_API_ID"))
api_hash = os.getenv("TELEGRAM_API_HASH")
string_session = os.getenv("TELEGRAM_STRING_SESSION")

client = TelegramClient(StringSession(string_session), api_id, api_hash)

# âœ… GOOGLE CLOUD STORAGE PRISIJUNGIMO DUOMENYS
credentials_json = os.getenv("GCP_SERVICE_ACCOUNT_JSON")
if not credentials_json:
    raise Exception("âŒ Google Cloud kredencialai nerasti!")

credentials_dict = json.loads(credentials_json)
credentials = service_account.Credentials.from_service_account_info(credentials_dict)
storage_client = storage.Client(credentials=credentials)
bucket_name = "telegram-media-storage"
bucket = storage_client.bucket(bucket_name)

# âœ… NUOLATINIAI KONSTANTAI
LAST_POST_FILE = "docs/last_post.json"
RSS_FILE = "docs/rss.xml"
MAX_POSTS = 5  # âœ… RSS faile visada bus tik 5 naujausi Ä¯raÅ¡ai
TIME_THRESHOLD = 65  # âœ… Tikriname paskutines 65 minutes
MAX_MEDIA_SIZE = 15 * 1024 * 1024  

# âœ… FUNKCIJA: Paskutinio posto ID Ä¯kÄ—limas
def load_last_post():
    if os.path.exists(LAST_POST_FILE):
        with open(LAST_POST_FILE, "r") as f:
            return json.load(f)
    return {"id": 0, "media": []}  # âœ… IÅ¡saugome ir media failÅ³ sÄ…raÅ¡Ä…

# âœ… FUNKCIJA: Paskutinio posto ID Ä¯raÅ¡ymas
def save_last_post(post_data):
    os.makedirs("docs", exist_ok=True)
    with open(LAST_POST_FILE, "w") as f:
        json.dump(post_data, f)

# âœ… FUNKCIJA: Pagrindinis RSS generavimas
async def create_rss():
    await client.connect()

    last_post = load_last_post()
    last_post_id = last_post.get("id", 0)
    last_media_files = set(last_post.get("media", []))  # âœ… IÅ¡saugoti jau naudoti media failai

    # âœ… UÅ¾tikriname, kad `utc_now` yra offset-aware
    utc_now = datetime.now(timezone.utc)

    # âœ… Gauname naujausius Telegram postus
    messages = await client.get_messages('Tsaplienko', limit=50)

    valid_messages = []
    for msg in messages:
        msg_date = msg.date.replace(tzinfo=timezone.utc)  # âœ… UÅ¾tikriname, kad `msg.date` yra offset-aware
        if msg.id <= last_post_id:
            logger.info(f"ğŸš« PraleidÅ¾iamas postas {msg.id}, nes jis jau buvo apdorotas.")
            continue
        if msg_date < utc_now - timedelta(minutes=TIME_THRESHOLD):
            logger.info(f"ğŸ•’ PraleidÅ¾iamas postas {msg.id}, nes jis senesnis nei {TIME_THRESHOLD} min.")
            continue
        if not msg.media:
            logger.info(f"ğŸ–¼ PraleidÅ¾iamas postas {msg.id}, nes jame nÄ—ra medijos.")
            continue

        valid_messages.append(msg)

    if not valid_messages:
        logger.warning("âš ï¸ NÄ—ra naujÅ³ Telegram postÅ³ su medija per paskutines 65 min.")
        exit(0)

    logger.info(f"âœ… Rasta {len(valid_messages)} naujÅ³ postÅ³ su medija.")

    # âœ… RSS generavimas
    fg = FeedGenerator()
    fg.title('Latest news')
    fg.link(href='https://www.mandarinai.lt/')
    fg.description('NaujienÅ³ kanalÄ… pristato www.mandarinai.lt')

    seen_media = set()
    added_entries = 0

    for msg in valid_messages:
        media_path = None
        blob_name = None

        try:
            media_path = await msg.download_media(file="./")
            if media_path:
                file_size = os.path.getsize(media_path)
                if file_size > MAX_MEDIA_SIZE:
                    logger.warning(f"âš ï¸ Failas {media_path} per didelis ({file_size} B), praleidÅ¾iamas.")
                    os.remove(media_path)
                    continue  # âŒ NEÄ®TRAUKTI Ä® RSS

                blob_name = os.path.basename(media_path)
                blob = bucket.blob(blob_name)

                # âœ… Jei failas jau buvo RSS, praleidÅ¾iame
                if blob_name in last_media_files:
                    logger.info(f"ğŸ”„ PraleidÅ¾iamas {blob_name}, nes jis jau buvo RSS.")
                    os.remove(media_path)
                    continue  # âŒ NEÄ®TRAUKTI Ä® RSS

                # âœ… Jei failas dar nÄ—ra Google Cloud Storage, Ä¯keliame
                if not blob.exists():
                    blob.upload_from_filename(media_path)
                    logger.info(f"âœ… Ä®keltas {blob_name} Ä¯ Google Cloud Storage")

                seen_media.add(blob_name)

                # âœ… Tik dabar pridedame Ä¯raÅ¡Ä… Ä¯ RSS
                fe = fg.add_entry()
                fe.title(msg.message[:30] if msg.message else "No Title")
                fe.description(msg.message if msg.message else "No Content")
                fe.pubDate(msg.date.replace(tzinfo=timezone.utc))  # âœ… UÅ¾tikriname, kad `pubDate` yra UTC
                fe.enclosure(url=f"https://storage.googleapis.com/{bucket_name}/{blob_name}", type='image/jpeg')

                added_entries += 1
                logger.info(f"ğŸ“Œ Ä® RSS Ä¯trauktas postas su media: {blob_name}")

            if media_path:
                os.remove(media_path)  # âœ… IÅ¡triname laikinÄ… failÄ…
        except Exception as e:
            logger.error(f"âŒ Klaida apdorojant media: {e}")
            if media_path:
                os.remove(media_path)  # âœ… IÅ¡triname failÄ…, jei nepavyko apdoroti

    # âœ… Jei nebuvo nÄ— vieno sÄ—kmingo Ä¯raÅ¡o su medija, nestatome RSS failo
    if added_entries == 0:
        logger.warning("âš ï¸ Visi postai buvo atmesti â€“ RSS nebus atnaujintas.")
        exit(0)

    # âœ… IÅ¡saugome naujÄ… RSS failÄ…
    with open(RSS_FILE, "wb") as f:
        f.write(fg.rss_str(pretty=True))

    save_last_post({"id": valid_messages[0].id, "media": list(seen_media)})
    logger.info("âœ… RSS failas sÄ—kmingai atnaujintas!")

# âœ… PAGRINDINIS PROCESO PALEIDIMAS
if __name__ == "__main__":
    loop = asyncio.get_event_loop()
    loop.run_until_complete(create_rss())