import os
import json
import asyncio
from telethon import TelegramClient
from telethon.sessions import StringSession
from feedgen.feed import FeedGenerator
import logging
import xml.etree.ElementTree as ET
from google.cloud import storage
from google.oauth2 import service_account

# Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Telegram API prisijungimo duomenys
api_id = int(os.getenv("TELEGRAM_API_ID"))
api_hash = os.getenv("TELEGRAM_API_HASH")
string_session = os.getenv("TELEGRAM_STRING_SESSION")

client = TelegramClient(StringSession(string_session), api_id, api_hash)

# Google Cloud nustatymai
credentials_json = os.getenv("GCP_SERVICE_ACCOUNT_JSON")
credentials_dict = json.loads(credentials_json)
credentials = service_account.Credentials.from_service_account_info(credentials_dict)

storage_client = storage.Client(credentials=credentials)
bucket_name = "telegram-media-storage"
bucket = storage_client.bucket(bucket_name)

# Failai
LAST_POST_FILE = "docs/last_post.json"
RSS_FILE = "docs/rss.xml"
MAX_POSTS = 5  # âœ… RSS visada turÄ—s bent 5 postus
MAX_MEDIA_SIZE = 15 * 1024 * 1024  # âœ… 15 MB ribojimas medijos failams

def load_last_post():
    """UÅ¾krauna paskutinio Ä¯raÅ¡o ID"""
    if os.path.exists(LAST_POST_FILE):
        with open(LAST_POST_FILE, "r") as f:
            return json.load(f)
    return {"id": 0}

def save_last_post(post_id):
    """IÅ¡saugo paskutinio Ä¯raÅ¡o ID"""
    os.makedirs("docs", exist_ok=True)
    with open(LAST_POST_FILE, "w") as f:
        json.dump({"id": post_id}, f)
    logger.info(f"âœ… Naujas `last_post.json`: {post_id}")

def load_existing_rss():
    """UÅ¾krauna esamus RSS Ä¯raÅ¡us ir uÅ¾tikrina, kad RSS visada turÄ—s bent 5 Ä¯raÅ¡us"""
    if not os.path.exists(RSS_FILE):
        return []

    try:
        tree = ET.parse(RSS_FILE)
        root = tree.getroot()
        channel = root.find("channel")
        items = channel.findall("item") if channel is not None else []
        return items[:MAX_POSTS]  # âœ… VISADA PALIEKAME BENT 5 Ä®RAÅ US
    except Exception as e:
        logger.error(f"âŒ Klaida skaitant RSS failÄ…: {e}")
        return []

async def create_rss():
    await client.connect()
    last_post = load_last_post()

    # âœ… Tikriname paskutinius 5 postus
    messages = await client.get_messages('Tsaplienko', limit=5)
    new_messages = [msg for msg in messages if msg.id > last_post.get("id", 0) and msg.media]

    if not new_messages:
        logger.info("âœ… NÄ—ra naujÅ³ postÅ³ su medija â€“ nutraukiame procesÄ….")
        exit(0)  # âœ… Taupome â€žGitHub Actionsâ€œ resursus

    logger.info(f"ðŸ†• Rasti {len(new_messages)} nauji postai su medija!")

    # âœ… UÅ¾krauname senus RSS Ä¯raÅ¡us
    existing_items = load_existing_rss()

    fg = FeedGenerator()
    fg.title('Latest news')
    fg.link(href='https://www.mandarinai.lt/')
    fg.description('NaujienÅ³ kanalÄ… pristato www.mandarinai.lt')

    # âœ… UÅ¾tikriname, kad RSS faile bÅ«tÅ³ bent 5 Ä¯raÅ¡ai su medija
    all_posts = new_messages + existing_items
    all_posts = all_posts[:MAX_POSTS]

    for msg in reversed(all_posts):
        fe = fg.add_entry()

        # âœ… Patikriname, ar tai `Telethon` objektas ar `XML Element`
        if isinstance(msg, ET.Element):
            fe.title(msg.find("title").text if msg.find("title") is not None else "No Title")
            fe.description(msg.find("description").text if msg.find("description") is not None else "No Content")
            fe.pubDate(msg.find("pubDate").text if msg.find("pubDate") is not None else "")
        else:
            # âœ… Dabar naudojame `msg.caption`, jei `msg.message` neegzistuoja
            title_text = (msg.message or msg.caption or "No Title")[:30]
            description_text = msg.message or msg.caption or "No Content"

            fe.title(title_text)
            fe.description(description_text)
            fe.pubDate(msg.date)

            # âœ… Jei yra keli paveikslÄ—liai, pridedame visus
            if msg.media:
                if hasattr(msg.media, "grouped_id"):
                    media_messages = await client.get_messages('Tsaplienko', min_id=msg.id - 5, max_id=msg.id + 5)
                    for media_msg in media_messages:
                        if media_msg.media and media_msg.grouped_id == msg.grouped_id:
                            media_path = await media_msg.download_media(file="./")
                            if media_path and os.path.getsize(media_path) <= MAX_MEDIA_SIZE:
                                blob_name = os.path.basename(media_path)
                                blob = bucket.blob(blob_name)

                                if not blob.exists():
                                    blob.upload_from_filename(media_path)
                                    blob.content_type = 'image/jpeg' if media_path.endswith(('.jpg', '.jpeg')) else 'video/mp4'
                                    logger.info(f"âœ… Ä®keltas {blob_name} Ä¯ Google Cloud Storage")

                                fe.enclosure(url=f"https://storage.googleapis.com/{bucket_name}/{blob_name}",
                                             type='image/jpeg' if media_path.endswith(('.jpg', '.jpeg')) else 'video/mp4')

                                os.remove(media_path)
                else:
                    media_path = await msg.download_media(file="./")
                    if media_path and os.path.getsize(media_path) <= MAX_MEDIA_SIZE:
                        blob_name = os.path.basename(media_path)
                        blob = bucket.blob(blob_name)

                        if not blob.exists():
                            blob.upload_from_filename(media_path)
                            blob.content_type = 'image/jpeg' if media_path.endswith(('.jpg', '.jpeg')) else 'video/mp4'
                            logger.info(f"âœ… Ä®keltas {blob_name} Ä¯ Google Cloud Storage")

                        fe.enclosure(url=f"https://storage.googleapis.com/{bucket_name}/{blob_name}",
                                     type='image/jpeg' if media_path.endswith(('.jpg', '.jpeg')) else 'video/mp4')

                        os.remove(media_path)

    save_last_post(new_messages[0].id)

    with open(RSS_FILE, "wb") as f:
        f.write(fg.rss_str(pretty=True))

    logger.info("âœ… RSS atnaujintas sÄ—kmingai!")

if __name__ == "__main__":
    loop = asyncio.get_event_loop()
    loop.run_until_complete(create_rss())
