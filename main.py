import asyncio
import os
import json
import logging
import xml.etree.ElementTree as ET
import datetime
import email.utils
from feedgen.feed import FeedGenerator
from google.cloud import storage
from google.oauth2 import service_account
from telethon import TelegramClient
from telethon.sessions import StringSession

# Nauji importai, reikalingi MIME tipams tvarkyti
import mimetypes
mimetypes.add_type('video/quicktime', '.mov')
mimetypes.add_type('video/mp4', '.mp4')

# ====================================================================
# LOGÅ² KONFIGÅªRACIJA:
# Nustatome praneÅ¡imÅ³ lygÄ¯ ir sukuriame logger'Ä¯, kuris fiksuos vykdymo informacijÄ….
# ====================================================================
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ====================================================================
# TELEGRAM PRISIJUNGIMO DUOMENYS:
# Gauname reikiamus duomenis (api_id, api_hash ir string_session) iÅ¡ aplinkos kintamÅ³jÅ³,
# kad galÄ—tume prisijungti prie Telegram API.
# ====================================================================
api_id = int(os.getenv("TELEGRAM_API_ID"))
api_hash = os.getenv("TELEGRAM_API_HASH")
string_session = os.getenv("TELEGRAM_STRING_SESSION")
client = TelegramClient(StringSession(string_session), api_id, api_hash)

# ====================================================================
# GOOGLE CLOUD STORAGE KONFIGÅªRACIJA:
# Gauname Google Cloud saugyklos (Storage) kredencialus ir inicijuojame klientÄ…,
# taip pat nustatome saugyklos pavadinimÄ….
# ====================================================================
credentials_json = os.getenv("GCP_SERVICE_ACCOUNT_JSON")
if not credentials_json:
    raise Exception("âŒ Google Cloud kredencialai nerasti!")
credentials_dict = json.loads(credentials_json)
credentials = service_account.Credentials.from_service_account_info(credentials_dict)
storage_client = storage.Client(credentials=credentials)
bucket_name = "telegram-media-storage"
bucket = storage_client.bucket(bucket_name)

# ====================================================================
# NUOLATINIAI KONSTANTAI:
# LAST_POST_FILE: Failas, kuriame saugomas paskutinio apdoroto Ä¯raÅ¡o ID.
# RSS_FILE: Failo kelias, kuriame bus iÅ¡saugotas sugeneruotas RSS srautas.
# MAX_POSTS: Maksimalus Ä¯raÅ¡Å³ skaiÄius RSS faile (visada 5 paskutiniai postai).
# MAX_MEDIA_SIZE: Maksimalus leidÅ¾iamas medijos failo dydis (15 MB).
# ====================================================================
LAST_POST_FILE = "docs/last_post.json"
RSS_FILE = "docs/rss.xml"
MAX_POSTS = 7
MAX_MEDIA_SIZE = 15 * 1024 * 1024

# ====================================================================
# FUNKCIJA: Ä®kelti paskutinio Ä¯raÅ¡o ID iÅ¡ failo.
# Jei failas neegzistuoja, grÄ…Å¾iname numatytÄ…jÄ… reikÅ¡mÄ™.
# ====================================================================
def load_last_post():
    if os.path.exists(LAST_POST_FILE):
        with open(LAST_POST_FILE, "r") as f:
            return json.load(f)
    return {"id": 0}

# ====================================================================
# FUNKCIJA: Ä®raÅ¡yti paskutinio Ä¯raÅ¡o ID Ä¯ failÄ….
# ====================================================================
def save_last_post(post_data):
    os.makedirs("docs", exist_ok=True)
    with open(LAST_POST_FILE, "w") as f:
        json.dump(post_data, f)

# ====================================================================
# FUNKCIJA: Nuskaityti esamo RSS failo Ä¯raÅ¡us.
# Jei RSS failas neegzistuoja arba yra sugadintas, grÄ…Å¾iname tuÅ¡ÄiÄ… sÄ…raÅ¡Ä….
# ====================================================================
def load_existing_rss():
    if not os.path.exists(RSS_FILE):
        return []
    try:
        tree = ET.parse(RSS_FILE)
        root = tree.getroot()
        channel = root.find("channel")
        return channel.findall("item") if channel is not None else []
    except Exception as e:
        logger.error(f"âŒ RSS failas sugadintas, kuriamas naujas: {e}")
        return []

# ====================================================================
# FUNKCIJA: Konvertuoti datÄ… Ä¯ datetime objektÄ….
# Jei data jau yra datetime, grÄ…Å¾iname jÄ…, o jei tai string â€“ konvertuojame.
# ====================================================================
def get_datetime(date_val):
    if isinstance(date_val, datetime.datetime):
        return date_val
    try:
        # Konvertuojame RFC 822 formato datÄ… Ä¯ datetime objektÄ….
        return email.utils.parsedate_to_datetime(date_val)
    except Exception:
        return datetime.datetime.min

# ====================================================================
# FUNKCIJA: Generuoti naujÄ… RSS srautÄ….
# ====================================================================
async def create_rss():
    # Prisijungiame prie Telegram API.
    await client.connect()
    last_post = load_last_post()
    
    # Gauname paskutines 14 Å¾inutes iÅ¡ kanalo "Tsaplienko".
    messages = await client.get_messages('Tsaplienko', limit=14)

    # Kintamasis albumo praneÅ¡imÅ³ tekstams:
    # Jei Å¾inutÄ—s priklauso vienam albumui, visoms bus naudojamas tas pats tekstas.
    grouped_texts = {}
    valid_posts = []  # ÄŒia saugosime Ä¯raÅ¡us, kurie turi tiek tekstÄ…, tiek medijos failÄ….

    # Iteruojame per gautas Å¾inutes.
    for msg in messages:
        # Patikriname, ar Å¾inutÄ—je yra tekstas (message arba caption).
        text = msg.message or getattr(msg, "caption", None)
        if not text:
            logger.warning(f"âš ï¸ PraleidÅ¾iamas postas {msg.id}, nes neturi teksto (title/description)")
            continue

        # Tikriname, ar Å¾inutÄ—je yra medijos failas.
        if not msg.media:
            logger.warning(f"âš ï¸ PraleidÅ¾iamas postas {msg.id}, nes neturi medijos failo")
            continue

        # Jei Å¾inutÄ— priklauso albumui, uÅ¾tikriname, kad visoms Å¾inutÄ—ms bÅ«tÅ³ naudojamas vienodas tekstas.
        if hasattr(msg.media, "grouped_id") and msg.media.grouped_id:
            if msg.media.grouped_id not in grouped_texts:
                grouped_texts[msg.media.grouped_id] = text
            else:
                text = grouped_texts[msg.media.grouped_id]

        valid_posts.append((msg, text))

    # Jei naujÅ³ tinkamÅ³ Ä¯raÅ¡Å³ nerasta â€“ paliekame esamÄ… RSS nepakitusiÄ….
    if not valid_posts:
        logger.info("NaujÅ³ validiÅ³ postÅ³ nerasta, RSS liks nepakitÄ™s.")
        return

    # Jei validiÅ³ Ä¯raÅ¡Å³ yra maÅ¾iau nei MAX_POSTS, papildomai pridedame senesnius Ä¯raÅ¡us iÅ¡ esamo RSS.
    if len(valid_posts) < MAX_POSTS:
        existing_items = load_existing_rss()
        additional_needed = MAX_POSTS - len(valid_posts)
        for item in existing_items[:additional_needed]:
            # Sukuriame "fake" praneÅ¡imÄ…, kad atitikÄiau duomenÅ³ struktÅ«rÄ….
            fake_msg = type("FakeMsg", (object,), {})()
            fake_msg.id = item.find("guid").text if item.find("guid") is not None else 0
            fake_msg.date = item.find("pubDate").text if item.find("pubDate") is not None else ""
            fake_text = item.find("description").text if item.find("description") is not None else ""
            valid_posts.append((fake_msg, fake_text))
            if len(valid_posts) >= MAX_POSTS:
                break

    # RÅ«Å¡iuojame Ä¯raÅ¡us pagal datÄ… maÅ¾Ä—jimo tvarka â€“ naujausi postai bus virÅ¡uje.
    # Konvertuojame datas Ä¯ datetime objektus, kad bÅ«tÅ³ galima atlikti teisingÄ… rÅ«Å¡iavimÄ….
    valid_posts.sort(key=lambda x: get_datetime(x[0].date), reverse=True)

    # Pradedame generuoti naujÄ… RSS srautÄ… su FeedGenerator.
    fg = FeedGenerator()
    fg.title('Latest news')                           # Kanalas: pavadinimas.
    fg.link(href='https://www.mandarinai.lt/')         # Kanalas: pagrindinÄ— nuoroda.
    fg.description('NaujienÅ³ kanalÄ… pristato www.mandarinai.lt')  # Kanalas: apraÅ¡ymas.

    seen_media = set()  # Saugojame jau panaudotus medijos failÅ³ pavadinimus,
                        # kad jÅ³ nebÅ«tÅ³ dubliuota RSS Ä¯raÅ¡e.

    # Iteruojame per kiekvienÄ… validÅ³ Ä¯raÅ¡Ä….
    for msg, text in valid_posts:
        fe = fg.add_entry()  # Pridedame naujÄ… Ä¯raÅ¡Ä… Ä¯ RSS srautÄ….
        fe.title(text[:30] if text else "No Title")  # Ä®raÅ¡o pavadinimas (pirmos 30 simboliÅ³).
        fe.link(href=f"https://www.mandarinai.lt/post/{msg.id}")  # Pridedame individualiÄ… nuorodÄ… Ä¯ Ä¯raÅ¡Ä….
        fe.description(text if text else "No Content")  # Ä®raÅ¡o apraÅ¡ymas (pilnas tekstas).
        fe.pubDate(msg.date)  # Ä®raÅ¡o paskelbimo data.

        # Apdorojame medijos failÄ… iÅ¡ Å¾inutÄ—s.
        try:
            # ParsisiunÄiame medijos failÄ… Ä¯ vietinÄ™ sistemÄ….
            media_path = await msg.download_media(file="./")
            if not media_path:
                logger.warning(f"âš ï¸ Nepavyko parsisiÅ³sti medijos iÅ¡ post {msg.id}")
                continue

            # Jei Å¾inutÄ—je yra daugiau nei vienas medijos failas (pvz., albumas),
            # pasirinkime mp4 failÄ…, jei toks yra (naudojama .lower() tikrinimui).
            if isinstance(media_path, list):
                mp4_files = [p for p in media_path if p.lower().endswith('.mp4')]
                if mp4_files:
                    media_path = mp4_files[0]
                else:
                    media_path = media_path[0]

            # Patikriname, ar medijos failo dydis nevirÅ¡ija nustatytos ribos.
            if os.path.getsize(media_path) > MAX_MEDIA_SIZE:
                logger.info(f"âŒ Didelis failas â€“ {media_path}, praleidÅ¾iamas")
                os.remove(media_path)
                continue

            # Nustatome medijos failo MIME tipÄ… naudojant mimetypes.
            content_type, _ = mimetypes.guess_type(media_path)
            if content_type is None:
                logger.warning(f"âš ï¸ Nepavyko nustatyti MIME tipo failui {media_path}, praleidÅ¾iamas")
                os.remove(media_path)
                continue

            # Nustatome medijos failo pavadinimÄ… ir paruoÅ¡iame failÄ… Ä¯kÄ—limui Ä¯ Google Cloud Storage.
            blob_name = os.path.basename(media_path)
            blob = bucket.blob(blob_name)

            # Jei failas dar nÄ—ra Ä¯keltas Ä¯ saugyklÄ…, atliekame Ä¯kÄ—limÄ….
            if not blob.exists():
                blob.upload_from_filename(media_path)
                blob.content_type = content_type
                logger.info(f"âœ… Ä®kÄ—lÄ—me {blob_name} Ä¯ Google Cloud Storage")
            else:
                logger.info(f"ğŸ”„ {blob_name} jau egzistuoja Google Cloud Storage")

            # Pridedame medijos failÄ… kaip RSS Ä¯raÅ¡o priedÄ… (<enclosure> elementÄ…).
            if blob_name not in seen_media:
                seen_media.add(blob_name)
                fe.enclosure(
                    url=f"https://storage.googleapis.com/{bucket_name}/{blob_name}",
                    type=content_type,
                    length=str(os.path.getsize(media_path))  # Nustatome failo dydÄ¯ (baitu skaiÄius).
                )

            # IÅ¡triname parsisiÅ³stÄ… medijos failÄ… iÅ¡ vietinÄ—s sistemos, kad neuÅ¾sikrautÅ³ saugykla.
            os.remove(media_path)
        except Exception as e:
            logger.error(f"âŒ Klaida apdorojant medijÄ… iÅ¡ post {msg.id}: {e}")

    # IÅ¡saugome paskutinio Ä¯raÅ¡o ID, kad vÄ—liau Å¾inotume nuo kurio laiko ieÅ¡koti naujÅ³ Å¾inuÄiÅ³.
    save_last_post({"id": valid_posts[0][0].id})

    # Ä®raÅ¡ome sugeneruotÄ… RSS srautÄ… Ä¯ failÄ…, naudodami graÅ¾Å³ formatavimÄ….
    with open(RSS_FILE, "wb") as f:
        f.write(fg.rss_str(pretty=True))

    logger.info("âœ… RSS atnaujintas sÄ—kmingai!")

# ====================================================================
# PAGRINDINIS PROGRAMOS PALEIDIMAS:
# PaleidÅ¾iame asinkroninÄ¯ pagrindinÄ¯ ciklÄ…, kuris generuoja RSS srautÄ….
# ====================================================================
if __name__ == "__main__":
    loop = asyncio.get_event_loop()
    loop.run_until_complete(create_rss())
